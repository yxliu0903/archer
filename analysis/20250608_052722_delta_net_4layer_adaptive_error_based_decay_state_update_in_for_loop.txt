                                                                  Unnamed: 0  Compress  Context Recall  Fuzzy Recall  Memorize  Noisy Recall  Selective Copy
0                                                           delta_net_4layer  0.441687        0.998683      0.216574  0.403352      0.997438        0.949954
1                             delta_net_4layer_adam_state_update_in_for_loop  0.337757        0.089304      0.024024  0.384297      0.023897        0.196143
2   delta_net_4layer_cosine_softmax_attention_error_gated_update_in_for_loop  0.444827        0.996742      0.165556  0.649914      0.988256        0.959016
3                      delta_net_4layer_cosine_softmax_attention_in_for_loop  0.436265        0.996512      0.162116  0.666553      0.990794        0.934717
4                            delta_net_4layer_decay_state_update_in_for_loop  0.435427        0.998480      0.218365  0.363693      0.996212        0.932825
5                      delta_net_4layer_error_gated_state_update_in_for_loop  0.439931        0.998649      0.227001  0.414150      0.998151        0.898605
6                        delta_net_4layer_layernorm_state_update_in_for_loop  0.425510        0.995487      0.166240  0.357337      0.992839        0.873239
7                         delta_net_4layer_momentum_state_update_in_for_loop  0.432281        0.992050      0.144458  0.369833      0.993707        0.879067
8                          delta_net_4layer_rmsprop_state_update_in_for_loop  0.333525        0.084800      0.030725  0.378087      0.031335        0.123251
9                       delta_net_4layer_sigmoid_similarity_gate_in_for_loop  0.429010        0.998919      0.180641  0.387742      0.998661        0.922861
10                            delta_net_4layer_softmax_attention_in_for_loop  0.427559        0.987641      0.160105  0.779396      0.977399        0.939016
11                                                    gated_delta_net_4layer  0.366612        0.999485      0.310357  0.586678      0.999478        0.996908
1. Overall Trend in Existing Variants
•  The original 4-layer DeltaNet already excels at Context Recall (≈1.0), Noisy Recall (≈1.0) and Selective Copy (≈0.95) but is notably weaker on Fuzzy Recall (≈0.22) and Memorize (≈0.40).
•  Gated DeltaNet trades a small drop in Compress (0.37→0.44) for clear gains in Fuzzy Recall (0.31) and Memorize (0.59), giving the best average so far (≈0.71).
•  Attempts that modified the *attention* (soft-max, cosine, RoPE-like) improved Memorize but **hurt Fuzzy Recall even further**, indicating that the bottleneck is not the read-out but the write policy.
•  Optimisation-style state updates (momentum, Adam, RMSProp) collapse performance except on Context / Noisy Recall, suggesting that heavy gradient–style perturbations destabilise the memory matrix.
•  Simple exponential decay (decay_state_update) preserved strong tasks but left Fuzzy / Memorize almost unchanged—over-writing too early seems to be the issue.

2. What Works / What Doesn’t
✓  Keep the error-driven Delta update: it is responsible for near-perfect Context & Noisy recall.
✗  Pure softmax-style attention or heavy optimiser dynamics: either erase useful memory or introduce noise.
✗  Uniform decay: removes useful associations even when the prediction is already correct.

3. New Idea – Adaptive Error-Based Decay (proposed here)
Motivation: only overwrite when the current prediction is actually wrong; otherwise keep the old memory intact.  This should
•  protect long-range information (Compress, Memorize), and
•  still adapt quickly when keys/values are noisy (Fuzzy & Noisy Recall).
Implementation (inside the for-loop):
    err_mag = ||u_i||                     # chunk-wise error magnitude
    g       = σ(γ·err_mag)               # adaptive gate (0→keep, 1→overwrite)
    S       = (1−g)·S + g·(k_iᵀ @ u_i)   # gated state update

4. Expected Impact per MAD Task
•  Compress / Memorize: smaller error → g≈0 → memory retained.
•  Fuzzy / Noisy Recall: larger error under noise → g→1 → fast correction.
•  Context Recall & Selective Copy: still rely on accurate associative memory, which is preserved.

5. Summary of Current Results vs. Goals
–  None of the tried variants surpass Gated DeltaNet on *all* tasks simultaneously.
–  The new adaptive gate explicitly addresses the main short-comings (Fuzzy & Memorize) while leaving the strengths untouched, giving it a realistic chance to beat Gated DeltaNet.
